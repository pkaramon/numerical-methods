#+title: Laboratorium 6 - Cakowanie numeryczne II
#+date: 21.04.2024r.
#+author: Piotr Karamon
#+setupfile: ../setupfile.org
#+LATEX_HEADER: \usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

* Treci zada
Obliczy przybli偶on warto caki:

$$\int_{-\infty}^{\infty} e^{-x^2} \cos(x) dx $$

   a) przy pomocy zo偶onych kwadratur (prostokt贸w, trapez贸w, Simpsona),
   b) przy pomocy cakowania adaptacyjnego,
   c) przy pomocy kwadratury Gaussa-Hermitea, obliczajc wartoci wz贸w i wag.

Por贸wna wydajno dla zadanej dokadnoci.
* Proste kwadratury
Funkcja kt贸r mamy scakowa ma wz贸r:
$$f(x) = e^{-x^2} \cos x $$

Narysujmy jej wykres

#+begin_src python :results file link :exports results
import numpy as np
import matplotlib.pyplot as plt
import scienceplots
plt.style.use('science')

x = np.linspace(-5, 5, 1000)
f = np.e**(-x**2)*np.cos(x)

fig, ax = plt.subplots(1, 1, figsize=(6, 4), dpi=150)
ax.plot(x, f, label='$f(x) = e^{-x^2} \cos x $')

fig.legend(loc='upper right', bbox_to_anchor=(0.4, 0.85), ncol=1)

path = './f.png'
fig.savefig(path)
return path
#+end_src

#+ATTR_LATEX: :placement [H] :width 12cm
#+CAPTION: Wykres funkcji $f(x)$.
#+RESULTS:
[[file:./f.png]]

Widzimy, 偶e wartoci funkcji bardzo szybko zbiegaj do zera, dziki czynnikowi $e^{-x^2}$.
Nasza funkcja jest parzysta zatem zamiast liczy oryginaln cak mo偶emy, j
przeksztaci.

$$\int_{-\infty}^{\infty} e^{-x^2} \cos(x) dx = 2\int_{0}^{\infty} e^{-x^2} \cos(x) dx = $$

Stosujemy dosy uniwersalne podstawienie $t = \frac{1}{1+x}$
$$ =  \int_0^1 2e^{-\left(\frac{1}{t} - 1\right)^2} \cos \left(\frac{1}{t} -1 \right) \cdot \frac{1}{t^2} dt  $$


Narysujemy teraz wykres funkcji podcakowej $f(t)$
#+begin_src python :results file link :exports results
import numpy as np
import matplotlib.pyplot as plt
import scienceplots
plt.style.use('science')

t = np.linspace(0.001, 1, 1000)
f = 2*np.e**(-(1/t-1)**2)*np.cos(1/t -1) * 1/t**2

fig, ax = plt.subplots(1, 1, figsize=(6, 4), dpi=150)
ax.plot(t, f, label=r'$f(t) =2e^{-\left(\frac{1}{t} - 1\right)^2} \cos \left(\frac{1}{t} -1 \right) \cdot \frac{1}{t^2}$', color='C1')

fig.legend( bbox_to_anchor=(0.55, 0.85), ncol=1)

path = './ft.png'
fig.savefig(path)
return path
#+end_src

#+ATTR_LATEX: :placement [H] :width 12cm
#+CAPTION: Wykres funkcji $f(t)$.
#+RESULTS:
[[file:./ft.png]]

W celu por贸wnania metod obliczmy dokadn warto tej caki przy u偶yciu biblioteki Sympy.

#+begin_src python  :results output :wrap example :exports both
from sympy import symbols, integrate, E, cos, oo

x = symbols('x')
fx = E ** (-x**2) * cos(x)
fx_int = integrate(fx, (x,-oo, oo))
print(fx_int)
print(fx_int.evalf())
#+end_src

#+RESULTS:
#+begin_example
sqrt(pi)*exp(-1/4)
1.38038844704314
#+end_example

Czyli dokadna warto caki jest r贸wna $I = \sqrt{\pi} \exp \left(-\frac{1}{4}\right)$
** Metoda prostokt贸w
$$S(f) =  \frac{b-a}{n} \sum_{i=0}^{n-1} f(x_i + \frac{1}{2} \cdot \frac{b-a}{n})$$
$$x_i = a + \frac{b-a}{n} \cdot i$$

#+begin_src python  :session first :exports code
import numpy as np

INTEGRAL = 1.38038844704314

def f(t):
    return 2*np.e**(-(1/t-1)**2) * np.cos(1/t-1)*1/t**2

def rectangle(f, a, b, n):
    xs = np.arange(a, b, (b-a)/n) + (b-a)/(2*n)
    integral = (b-a)/n * np.sum(f(xs))
    return integral
#+end_src

#+RESULTS:

#+begin_src python  :results output  :session first :exports results :wrap export latex
import pandas as pd
import numpy as np

def results_table(approx, integral, ns, table_title):
    df = pd.DataFrame(dict(n=ns))
    df['S(f)'] = df['n'].map(lambda n: approx(n))
    df['Abs Error'] = np.abs(df['S(f)'] - integral)
    df['Relative Error [\%]'] = np.abs(df['S(f)'] - integral) / integral * 100

    latex_table = df.to_latex(index=False, escape=False,float_format= lambda x: f'{x:.10f}')

    # Adding LaTeX table environment
    full_latex_document = f"""
    \\begin{{table}}[H]
    \\centering
    \\caption{{{table_title}}}
    {latex_table}
    \\end{{table}}
    """
    print(full_latex_document)

results_table(lambda n: rectangle(f, 0, 1, n), INTEGRAL, [1,2,5,10, 20, 50, 100, 200, 500, 1000],
              'Wyniki dla zo偶onej kwadratury prostokt贸w')
#+end_src

#+RESULTS:
#+begin_export latex

    \begin{table}[H]
    \centering
    \caption{Wyniki dla zo偶onej kwadratury prostokt贸w}
    \begin{tabular}{rrrr}
\toprule
n & S(f) & Abs Error & Relative Error [\%] \\
\midrule
1 & 1.5901288828 & 0.2097404357 & 15.1943053549 \\
2 & 1.5013067649 & 0.1209183178 & 8.7597312253 \\
5 & 1.4074352856 & 0.0270468386 & 1.9593643111 \\
10 & 1.3816902507 & 0.0013018036 & 0.0943070513 \\
20 & 1.3808055337 & 0.0004170867 & 0.0302151676 \\
50 & 1.3804551184 & 0.0000666713 & 0.0048298959 \\
100 & 1.3804051140 & 0.0000166670 & 0.0012074107 \\
200 & 1.3803926137 & 0.0000041667 & 0.0003018487 \\
500 & 1.3803891137 & 0.0000006667 & 0.0000482956 \\
1000 & 1.3803886137 & 0.0000001667 & 0.0000120739 \\
\bottomrule
\end{tabular}

    \end{table}
#+end_export
** Metoda trapez贸w

$$S(f) = \frac{1}{2}\cdot \frac{b-a}{n} \sum_{i=0}^{n-1} [f(x_i) + f(x_{i+1})]$$

#+begin_src python :results output :wrap example :session first :exports code
def trapezoid(f, a, b, n):
    dx = (b-a)/n
    xs = np.linspace(a, b, n+1)
    integral = 0
    for i in range(1, n+1):
        integral += dx*(f(xs[i]) + f(xs[i-1])) /2
    return integral
#+end_src

By unikn dzielenia przez zero $a$ ustawiamy na liczb bardzo blisk zera (=1e-10=).
#+begin_src python  :session first :exports results :results output :wrap export latex
results_table(lambda n: trapezoid(f, 1e-10, 1, n), INTEGRAL, [1,2,5,10, 20, 50, 100, 200, 500, 1000],
              'Wyniki dla zo偶onej kwadratury trapez贸w')
#+end_src

#+RESULTS:
#+begin_export latex

    \begin{table}[H]
    \centering
    \caption{Wyniki dla zo偶onej kwadratury trapez贸w}
    \begin{tabular}{rrrr}
\toprule
n & S(f) & Abs Error & Relative Error [\%] \\
\midrule
1 & 0.9999999999 & 0.3803884471 & 27.5566234967 \\
2 & 1.2950644417 & 0.0853240054 & 6.1811590472 \\
5 & 1.3474028839 & 0.0329855631 & 2.3895855689 \\
10 & 1.3774190848 & 0.0029693623 & 0.2151106297 \\
20 & 1.3795546677 & 0.0008337793 & 0.0604017891 \\
50 & 1.3802551084 & 0.0001333387 & 0.0096595026 \\
100 & 1.3803551134 & 0.0000333337 & 0.0024148034 \\
200 & 1.3803801137 & 0.0000083334 & 0.0006036963 \\
500 & 1.3803871137 & 0.0000013333 & 0.0000965912 \\
1000 & 1.3803881137 & 0.0000003333 & 0.0000241478 \\
\bottomrule
\end{tabular}

    \end{table}
#+end_export
** Metoda Simpsona

$$S(f) = \frac{b-a}{6}\sum_{i=1}^{n/2} \left[ f(x_{2i-2}) + 4f(x_{2x-1}) + f(x_{2i}) \right]$$

#+begin_src python :session first
def simpson_rule(f, a, b, n):
    if n % 2 == 1: # n musi by parzyste
        n += 1
    dx = (b-a)/n
    xs = np.linspace(a, b, n+1)
    integral = 0
    for i in range(1, n //2 +1):
        integral += dx/3*( f(xs[2*i-2]) + 4*f(xs[2*i-1]) + f(xs[2*i]) )
    return integral
#+end_src

#+RESULTS:

Podobnie jak w przypadku trapez贸w zamiast $a = 0$ u偶ywamy =1e-10=
#+begin_src python  :session first :exports results :results output :wrap export latex
results_table(lambda n: simpson_rule(f, 1e-10, 1, n), INTEGRAL, [1,2,5,10, 20, 50, 100, 200, 500, 1000],
              'Wyniki dla zo偶onej kwadratury Simpsona')
#+end_src

#+RESULTS:
#+begin_export latex

    \begin{table}[H]
    \centering
    \caption{Wyniki dla zo偶onej kwadratury Simpsona}
    \begin{tabular}{rrrr}
\toprule
n & S(f) & Abs Error & Relative Error [\%] \\
\midrule
1 & 1.3934192556 & 0.0130308085 & 0.9439957693 \\
2 & 1.3934192556 & 0.0130308085 & 0.9439957693 \\
5 & 1.3936081633 & 0.0132197162 & 0.9576808810 \\
10 & 1.3874244850 & 0.0070360380 & 0.5097143501 \\
20 & 1.3802665287 & 0.0001219183 & 0.0088321756 \\
50 & 1.3803884726 & 0.0000000256 & 0.0000018527 \\
100 & 1.3803884484 & 0.0000000013 & 0.0000000964 \\
200 & 1.3803884471 & 0.0000000001 & 0.0000000060 \\
500 & 1.3803884470 & 0.0000000000 & 0.0000000002 \\
1000 & 1.3803884470 & 0.0000000000 & 0.0000000000 \\
\bottomrule
\end{tabular}

    \end{table}
#+end_export

*Wnioski*: Z por贸d prostych kwadratur zdecydowanie najlepsze wyniki otrzymujemy w
przypadku metody Simpsona. Ta metoda nawet dla maych $n$ daje dobre
przybli偶enie. Metody prostokt贸w oraz trapez贸w daj zadawalajce rezultaty ale
tylko gdy $n$ jest du偶e, dla maych iloci przedzia贸w bdy s zdecydowanie za
du偶e. Wszystkie trzy metody s bardzo atwe w implementacji, a zatem je偶eli
chcemy mie prosty algorytm liczcy dosy dokadnie caki dla wielu
funkcji to powinnimy wybra metod Simpsona.
* Cakowanie adaptacyjne
Bdziemy cakowa adaptacyjnie przy u偶yciu kwadratury Simpsona.
Mamy zadane $\Delta$, czyli dokadno z jak chcemy obliczy cak.
$S(a,b)$ oznacza warto kwadratury Simpsona dla przedziau $(a, b)$ Bdziemy postpowa w nastpujcy spos贸b:
1) Je偶eli $|S(a,b) - S(a, \frac{a+b}{2}) - S(\frac{a+b}{2}, b)| < 15 \Delta$,
   to koczymy.
2) Je偶eli powy偶sza nier贸wno nie jest speniona to stosujemy procedur rekurencyjnie
   do przedzia贸w $[a, \frac{a+b}{2}]$, $[\frac{a+b}{2}, b]$ w ka偶dym z nich $\Delta' =\frac{\Delta}{2}$.



#+begin_src python :results output :session first :exports code
def adaptive_integral(f, a, b, delta=1e-5, max_level=10):
    initial_estimate = simpson_quadrature(f, a, b)
    points = [a]
    result = recursive_integral(f, a, b, initial_estimate, delta, 0, max_level, points)
    points.append(b)
    return result, np.array(points)


def simpson_quadrature(f, a, b):
    h = (b-a)/2
    return  h/3 * (f(a) + 4*f(a+h) + f(b))

def recursive_integral(f, a, b, S, delta, level, max_level, points):
    if level == max_level:
        return float('nan')

    S1 = simpson_quadrature(f, a, (a + b) / 2)
    S2 = simpson_quadrature(f, (a + b) / 2, b)

    points.append((a+b)/2)

    if abs(S1 + S2 - S) < 15*delta:
        return S1 + S2
    else:
        left = recursive_integral(f, a, (a + b) / 2, S1, delta / 2, level + 1, max_level, points)
        right = recursive_integral(f, (a + b) / 2, b, S2, delta / 2, level + 1, max_level, points)
        return left + right
#+end_src

#+RESULTS:

#+begin_src python :session first :results output :wrap export latex :exports results
deltas = [
    0.1,
    0.01,
    0.001,
    0.0001,
    0.00001,
    0.000001,
    0.0000001,
    0.00000001,
    0.000000001,
    0.0000000001,
]
df = pd.DataFrame(dict(delta=deltas))

df['Approx'] = df['delta'].map(lambda d: adaptive_integral(f,1e-10, 1,d, 100000)[0])
df['$n$'] = df['delta'].map(lambda d: len(adaptive_integral(f,1e-10, 1,d, 100000)[1]))
df['Abs Error'] = np.abs(df['Approx'] - INTEGRAL)
df['Relative Error [\%]'] = np.abs(df['Approx'] - INTEGRAL) / INTEGRAL * 100

df = df.rename(columns={'delta': '$\Delta$'})

latex_table = df.to_latex(index=False, escape=False,float_format= lambda x: f'{x:.10f}')


full_latex_document = f"""
\\begin{{table}}[H]
\\centering
\\caption{{Wyniki dla cakowania adaptacyjnego przy u偶yciu kwadratury Simpsona.}}
{latex_table}
\\end{{table}}
"""
print(full_latex_document)
#+end_src

#+RESULTS:
#+begin_export latex

\begin{table}[H]
\centering
\caption{Wyniki dla cakowania adaptacyjnego przy u偶yciu kwadratury Simpsona.}
\begin{tabular}{rrrrr}
\toprule
$\Delta$ & Approx & $n$ & Abs Error & Relative Error [\%] \\
\midrule
0.1000000000 & 1.4325593237 & 3 & 0.0521708766 & 3.7794344584 \\
0.0100000000 & 1.4325593237 & 3 & 0.0521708766 & 3.7794344584 \\
0.0010000000 & 1.3804846333 & 11 & 0.0000961863 & 0.0069680574 \\
0.0001000000 & 1.3803422211 & 17 & 0.0000462260 & 0.0033487668 \\
0.0000100000 & 1.3803879528 & 33 & 0.0000004943 & 0.0000358053 \\
0.0000010000 & 1.3803883542 & 51 & 0.0000000929 & 0.0000067277 \\
0.0000001000 & 1.3803884383 & 93 & 0.0000000087 & 0.0000006336 \\
0.0000000100 & 1.3803884462 & 159 & 0.0000000008 & 0.0000000583 \\
0.0000000010 & 1.3803884466 & 285 & 0.0000000004 & 0.0000000286 \\
0.0000000001 & 1.3803884470 & 525 & 0.0000000000 & 0.0000000004 \\
\bottomrule
\end{tabular}

\end{table}
#+end_export


#+begin_src python :session first  :exports none
import math
import numpy as np
import matplotlib.pyplot as plt
import scienceplots

plt.style.use('science')

fig, axes = plt.subplots(math.ceil(len(deltas)/2), 2, figsize=(8, 8), dpi=300)

for ax, delta in zip(axes.flatten(), deltas):
    x = np.linspace(1e-10, 1, 100)
    y = f(x)
    ax.plot(x,y, label='y=f(t)')

    _, points = adaptive_integral(f, 1e-10, 1, delta=delta, max_level=1e5)
    ax.scatter(points, f(points),  label=rf'$\Delta = {delta}, \; n = {len(points)}$', c='C1', s=10)

    ax.legend()
plt.tight_layout()
path = 'adaptive.png'
fig.savefig(path)
#+end_src

#+RESULTS:
: None


#+ATTR_LATEX: :placement [H]
#+CAPTION: W zielonych punktach obliczana bya warto funkcji w wyniku cakowania adaptacyjnego.
$n$ oznacza ilo puntk贸w w kt贸rych to obliczylimy warto funkcji $f(t)$
file:./adaptive.png

*Wnioski*: Metoda cakowania adaptycjnego daje imponujce wyniki.
Przy niewielkich ilociach przedzia贸w bd zbiega szybko do zera.
Na wykresach widzimy r贸wnie偶 ``adaptacyjno`` tej metody.
Spogldajc na wykres dla $\Delta = 1e-5$ widzimy, 偶e najwiksze
zagszczenie wz贸w jest przy minimum lokalnym w okolicy $0.4$,
poniewa偶 funkcja przyjmuje tam do zo偶nych ksztat.
Natomiast w przedziale $[0,0.2]$ funkcja jest bliska linii prostej i
w tym przedziale jest niewiele wz贸w, poniewa偶 jest to prosty kszat kt贸ry
atwo jest przybli偶y.
Ogromn zalet tej metody jest mo偶liwo wybrania dokadnoci z jak chcemy
otrzyma warto caki.
* Kwadrautra Gaussa-Hermite'a
Wielomiany Hermite'a to wieloniamy speniajce r贸wnanie

$$H_n(x) = (-1)^n e^{x^2} \frac{d^n}{dx^n} e^{-x^2}$$

Speniaj one rekurecyjne r贸wnanie:

$$H_0(x) = 1$$
$$H_{n+1}(x) = 2xH_{n}(x) - H_n'(x)$$

U偶ywajc biblioteki Sympy mo偶emy atwo wyznaczy wzory tych wielomian贸w

#+begin_src python :results output :session hermite
from sympy import symbols,lambdify, diff, expand, latex
x = symbols('x')

def hermite(n):
    if n == 0:
        return 1
    lower = hermite(n-1)
    return x*2*lower - diff(lower, x)
#+end_src

#+RESULTS:


#+begin_src python :session hermite :results output :wrap export latex :exports results
print(r'\begin{align*}')
for i in range(0, 12):
    print(rf" H_{{{i}}}(x) &= {latex(expand(hermite(i)))}\\ ")
print(r'\end{align*}')
#+end_src

#+RESULTS:
#+begin_export latex
\begin{align*}
 H_{0}(x) &= 1\\
 H_{1}(x) &= 2 x\\
 H_{2}(x) &= 4 x^{2} - 2\\
 H_{3}(x) &= 8 x^{3} - 12 x\\
 H_{4}(x) &= 16 x^{4} - 48 x^{2} + 12\\
 H_{5}(x) &= 32 x^{5} - 160 x^{3} + 120 x\\
 H_{6}(x) &= 64 x^{6} - 480 x^{4} + 720 x^{2} - 120\\
 H_{7}(x) &= 128 x^{7} - 1344 x^{5} + 3360 x^{3} - 1680 x\\
 H_{8}(x) &= 256 x^{8} - 3584 x^{6} + 13440 x^{4} - 13440 x^{2} + 1680\\
 H_{9}(x) &= 512 x^{9} - 9216 x^{7} + 48384 x^{5} - 80640 x^{3} + 30240 x\\
 H_{10}(x) &= 1024 x^{10} - 23040 x^{8} + 161280 x^{6} - 403200 x^{4} + 302400 x^{2} - 30240\\
 H_{11}(x) &= 2048 x^{11} - 56320 x^{9} + 506880 x^{7} - 1774080 x^{5} + 2217600 x^{3} - 665280 x\\
\end{align*}
#+end_export

Wielomiany te s ortogonalne z funkcj wagow $w(x) = e^{-x^2}$, czyli
$$ \int _{-\infty}^{\infty} H_m(x) H_n(x) e^{-x^2} dx = 0, \quad \text{dla}\quad m \ne e $$

Bdziemy postpowa w nastpujcy spos贸b:
1) Dla zadanego $n$ znajdziemy miejsca zerowe $H_{n}(x)$ numerycznie funkcj biblioteczn.
2) Rozwi偶emy ukad r贸wna w celu uzyskania wag
   \begin{equation*}
   \left[
   \begin{array}{ccc}
   H_0(x_1) & \cdots & H_0(x_n) \\
   \vdots & \ddots & \vdots \\
   H_{n-2}(x_1) & \cdots & H_{n-2}(x_n) \\
   H_{n-1}(x_1) & \cdots & H_{n-1}(x_n)
   \end{array}
   \right]
   \left[
   \begin{array}{c}
   w_1 \\
   w_2 \\
   \vdots \\
   w_n
   \end{array}
   \right]
   =
   \left[
   \begin{array}{c}
   \int_{-\infty}^{\infty} w(x) H_0(x)\, dx=\sqrt{\pi} \\
   0 \\
   \vdots \\
   0
   \end{array}
   \right]
   \end{equation*}
3) Warto caki policzymy ze wzoru:
   $$ \int_{-\infty}^{\infty} e^{-x^2} f(x) dx \approx \sum_{i=1}^{n} w_i f(x_i)$$

Tworzymy funkcj kt贸ra obliczy miejsca zerowe oraz potrzebne wagi.

#+begin_src python :results output :session hermite
import numpy as np
from numpy.polynomial import  hermite
from numpy.polynomial.hermite import hermroots, Hermite

def hermite_roots_weights(n):
    roots = hermroots([0]*n +[1])
    Hs = [Hermite([0] * i + [1]) for i in range(0, n)]

    A = np.zeros((n,n))
    for i in range(n):
        for j in range(n):
            A[i,j] = Hs[i](roots[j])
    b = np.zeros(n)
    b[0] = np.sqrt(np.pi)

    weights = np.linalg.solve(A, b)
    return np.array(roots), np.array(weights)
#+end_src

#+RESULTS:


#+begin_src python :session hermite :results output :wrap export latex :exports results
import pandas as pd

n = 5
roots, weights = hermite_roots_weights(n)
df = pd.DataFrame(dict(i = list(range(1,n+1))))
df['$x_i$'] = roots
df['$w_i$'] = weights

latex_table = df.to_latex(index=False, escape=False,float_format= lambda x: f'{x:.10f}')
full_latex_document = f"""
\\begin{{table}}[H]
\\centering
\\caption{{Wagi i wzy dla $n=5$}}
{latex_table}
\\end{{table}}
"""
print(full_latex_document)
#+end_src

#+RESULTS:
#+begin_export latex

\begin{table}[H]
\centering
\caption{Wagi i wzy dla $n=5$}
\begin{tabular}{rrr}
\toprule
i & $x_i$ & $w_i$ \\
\midrule
1 & -2.0201828705 & 0.0199532421 \\
2 & -0.9585724646 & 0.3936193232 \\
3 & 0.0000000000 & 0.9453087205 \\
4 & 0.9585724646 & 0.3936193232 \\
5 & 2.0201828705 & 0.0199532421 \\
\bottomrule
\end{tabular}

\end{table}
#+end_export


I funkcj kt贸ra oblicza cak

#+begin_src python :session hermite
def hermite_approx(f, n):
    roots, weights = hermite_roots_weights(n)
    return np.sum(f(roots) * weights)
#+end_src


#+begin_src python :session hermite :results output :exports results :wrap export latex
import pandas as pd

INTEGRAL = 1.38038844704314

def f(x):
    return np.cos(x)

df = pd.DataFrame(dict(n=[1,2,3,4,5,6,7,8,9,10]))
df['Approx'] = df['n'].map(lambda n: hermite_approx(f, n))
df['Abs Error'] = np.abs(df['Approx'] - INTEGRAL)
df['Relative Error [\%]'] = np.abs(df['Approx'] - INTEGRAL) / INTEGRAL * 100

latex_table = df.to_latex(index=False, escape=False,float_format= lambda x: f'{x:.12f}')

full_latex_document = f"""
\\begin{{table}}[H]
\\centering
\\caption{{Wyniki dla cakowania kwadratur Gaussa-Hermite'a.}}
{latex_table}
\\end{{table}}
"""
print(full_latex_document)
#+end_src

#+RESULTS:
#+begin_export latex

\begin{table}[H]
\centering
\caption{Wyniki dla cakowania kwadratur Gaussa-Hermite'a.}
\begin{tabular}{rrrr}
\toprule
n & Approx & Abs Error & Relative Error [\%] \\
\midrule
1 & 1.772453850906 & 0.392065403862 & 28.402541668774 \\
2 & 1.347498463717 & 0.032889983326 & 2.382661445536 \\
3 & 1.382033071388 & 0.001644624345 & 0.119142140637 \\
4 & 1.380329757161 & 0.000058689882 & 0.004251693211 \\
5 & 1.380390075936 & 0.000001628893 & 0.000118002474 \\
6 & 1.380388410051 & 0.000000036992 & 0.000002679855 \\
7 & 1.380388447754 & 0.000000000711 & 0.000000051503 \\
8 & 1.380388447031 & 0.000000000012 & 0.000000000858 \\
9 & 1.380388447043 & 0.000000000000 & 0.000000000013 \\
10 & 1.380388447043 & 0.000000000000 & 0.000000000000 \\
\bottomrule
\end{tabular}

\end{table}
#+end_export



*Wnioski*: Widzimy ogromn przewag kwadratury Gaussa-Hermite'a nad innymi metodami.
Dokadno podobn jak dla $n=10$ w tej metodzie mo偶emy zaobserwowa w poprzednich sposobach dla $n=1000$.
Co sprawia, 偶e po wyliczeniu miejsc zerowych oraz wag, kwadratura Gaussa-Hermite'a jest
znaczenie bardziej oszczdna obliczeniowo. Bd wzgldny na poziomie poni偶ej 1% widzimy ju偶
przy $n=3$. Zalet tej metody jest r贸wnie偶 to, 偶e wietnie dziaa ona na przedziale $[-\infty, \infty]$
bez 偶adnych przeksztace. Wad natomiast jest maa uniwersalno.
* Podsumowanie
Analiza por贸wnawcza prostych kwadratur, cakowania adaptacyjnego i kwadratury Gaussa-Hermitea potwierdza ich r贸偶norodn efektywno dla zadanego problemu cakowania. Metoda Simpsona, charakteryzujca si wyjtkow dokadnoci nawet przy mniejszej liczbie podzia贸w $$
wykazuje si najlepsz efektywnoci wr贸d prostych kwadratur.
Cakowanie adaptacyjne, znaczco zwiksza precyzj wyniku, szczeg贸lnie w rejonach, gdzie funkcja wykazuje skomplikowane zachowanie, przy jednoczesnym ograniczeniu liczby potrzebnych oblicze. Natomiast kwadratura Gaussa-Hermitea, cho wymaga wstpnego wyznaczenia miejsc zerowych i wag, okazuje si by najbardziej wydajna obliczeniowo, gwarantujc wysok dokadno przy znacznie ni偶szym
koszcie obliczeniowym.
* Bibliografia
+ Marian Bubak, Katarzyna Rycerz: /Metody Obliczeniowe w Nauce i Technice. Kwadratury/
+ [[https://en.wikipedia.org/wiki/Gauss%E2%80%93Hermite_quadrature][Gauss-Hermite Quadrature]]
+ [[https://en.wikipedia.org/wiki/Hermite_polynomials][Hermite polynomials]]
